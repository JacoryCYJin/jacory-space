---
title: "AWS äº‘æœåŠ¡å®è·µæŒ‡å—"
excerpt: "æ·±å…¥å­¦ä¹  AWS äº‘æœåŠ¡ï¼ŒæŒæ¡ EC2ã€S3ã€RDSã€Lambda ç­‰æ ¸å¿ƒæœåŠ¡ï¼Œå­¦ä¼šæ„å»ºå¯æ‰©å±•çš„äº‘åŸç”Ÿåº”ç”¨ã€‚"
date: "2024-01-06"
category: "cloud"
tags: ["aws", "cloud", "ec2", "lambda", "devops"]
cover: "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop"
author: "Jacory"
readTime: "24 min"
---

# AWS äº‘æœåŠ¡å®è·µæŒ‡å—

Amazon Web Services (AWS) æ˜¯å…¨çƒé¢†å…ˆçš„äº‘è®¡ç®—å¹³å°ï¼Œæä¾›è¶…è¿‡ 200 é¡¹æœåŠ¡ã€‚æœ¬æ–‡å°†å¸¦ä½ ä»åŸºç¡€å¼€å§‹ï¼Œç³»ç»Ÿå­¦ä¹  AWS æ ¸å¿ƒæœåŠ¡å’Œæœ€ä½³å®è·µã€‚

## AWS æ ¸å¿ƒæ¦‚å¿µ

### äº‘è®¡ç®—æœåŠ¡æ¨¡å‹

â˜ï¸ **IaaS (åŸºç¡€è®¾æ–½å³æœåŠ¡)**ï¼šEC2ã€VPCã€EBS  
âš™ï¸ **PaaS (å¹³å°å³æœåŠ¡)**ï¼šElastic Beanstalkã€Lambda  
ğŸ“± **SaaS (è½¯ä»¶å³æœåŠ¡)**ï¼šWorkSpacesã€Chime  

### AWS å…¨çƒåŸºç¡€è®¾æ–½

ğŸŒ **åŒºåŸŸ (Regions)**ï¼šåœ°ç†ä½ç½®ç‹¬ç«‹çš„æ•°æ®ä¸­å¿ƒé›†ç¾¤  
ğŸ¢ **å¯ç”¨åŒº (Availability Zones)**ï¼šåŒºåŸŸå†…çš„ç‹¬ç«‹æ•°æ®ä¸­å¿ƒ  
âš¡ **è¾¹ç¼˜ç«™ç‚¹ (Edge Locations)**ï¼šå†…å®¹åˆ†å‘ç½‘ç»œèŠ‚ç‚¹  

### æ ¸å¿ƒæœåŠ¡æ¦‚è§ˆ

| ç±»åˆ« | æœåŠ¡ | ç”¨é€” |
|------|------|------|
| è®¡ç®— | EC2, Lambda, ECS | è™šæ‹ŸæœåŠ¡å™¨ã€æ— æœåŠ¡å™¨è®¡ç®— |
| å­˜å‚¨ | S3, EBS, EFS | å¯¹è±¡å­˜å‚¨ã€å—å­˜å‚¨ã€æ–‡ä»¶å­˜å‚¨ |
| æ•°æ®åº“ | RDS, DynamoDB, Aurora | å…³ç³»å‹ã€NoSQL æ•°æ®åº“ |
| ç½‘ç»œ | VPC, CloudFront, Route 53 | è™šæ‹Ÿç½‘ç»œã€CDNã€DNS |
| å®‰å…¨ | IAM, KMS, WAF | èº«ä»½ç®¡ç†ã€åŠ å¯†ã€é˜²ç«å¢™ |

## EC2 è™šæ‹ŸæœåŠ¡å™¨

### å®ä¾‹åˆ›å»ºå’Œç®¡ç†

```bash
# ä½¿ç”¨ AWS CLI åˆ›å»º EC2 å®ä¾‹
# é¦–å…ˆé…ç½® AWS CLI
aws configure

# åˆ›å»ºå¯†é’¥å¯¹
aws ec2 create-key-pair --key-name my-key-pair --query 'KeyMaterial' --output text > my-key-pair.pem
chmod 400 my-key-pair.pem

# åˆ›å»ºå®‰å…¨ç»„
aws ec2 create-security-group \
    --group-name my-security-group \
    --description "My security group"

# æ·»åŠ å…¥ç«™è§„åˆ™ï¼ˆSSH å’Œ HTTPï¼‰
aws ec2 authorize-security-group-ingress \
    --group-name my-security-group \
    --protocol tcp \
    --port 22 \
    --cidr 0.0.0.0/0

aws ec2 authorize-security-group-ingress \
    --group-name my-security-group \
    --protocol tcp \
    --port 80 \
    --cidr 0.0.0.0/0

# å¯åŠ¨ EC2 å®ä¾‹
aws ec2 run-instances \
    --image-id ami-0abcdef1234567890 \
    --count 1 \
    --instance-type t3.micro \
    --key-name my-key-pair \
    --security-groups my-security-group \
    --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=my-web-server}]'
```

### ç”¨æˆ·æ•°æ®è„šæœ¬

```bash
#!/bin/bash
# ç”¨æˆ·æ•°æ®è„šæœ¬ - åœ¨å®ä¾‹å¯åŠ¨æ—¶è‡ªåŠ¨æ‰§è¡Œ

# æ›´æ–°ç³»ç»Ÿ
yum update -y

# å®‰è£… Docker
yum install -y docker
systemctl start docker
systemctl enable docker
usermod -a -G docker ec2-user

# å®‰è£… Node.js
curl -fsSL https://rpm.nodesource.com/setup_18.x | bash -
yum install -y nodejs

# å®‰è£… Nginx
yum install -y nginx
systemctl start nginx
systemctl enable nginx

# é…ç½® Nginx
cat > /etc/nginx/conf.d/app.conf << 'EOF'
server {
    listen 80;
    server_name _;
    
    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}
EOF

systemctl reload nginx

# éƒ¨ç½²åº”ç”¨
cd /home/ec2-user
git clone https://github.com/your-username/your-app.git
cd your-app
npm install
pm2 start app.js --name "web-app"
pm2 startup
pm2 save
```

### Auto Scaling è‡ªåŠ¨æ‰©ç¼©å®¹

```json
{
  "LaunchTemplateName": "my-launch-template",
  "LaunchTemplateData": {
    "ImageId": "ami-0abcdef1234567890",
    "InstanceType": "t3.micro",
    "KeyName": "my-key-pair",
    "SecurityGroupIds": ["sg-12345678"],
    "UserData": "base64-encoded-user-data-script",
    "TagSpecifications": [
      {
        "ResourceType": "instance",
        "Tags": [
          {
            "Key": "Name",
            "Value": "auto-scaling-instance"
          }
        ]
      }
    ]
  }
}
```

```bash
# åˆ›å»ºå¯åŠ¨æ¨¡æ¿
aws ec2 create-launch-template --cli-input-json file://launch-template.json

# åˆ›å»º Auto Scaling ç»„
aws autoscaling create-auto-scaling-group \
    --auto-scaling-group-name my-asg \
    --launch-template LaunchTemplateName=my-launch-template,Version=1 \
    --min-size 1 \
    --max-size 5 \
    --desired-capacity 2 \
    --availability-zones us-west-2a us-west-2b

# åˆ›å»ºæ‰©ç¼©å®¹ç­–ç•¥
aws autoscaling put-scaling-policy \
    --auto-scaling-group-name my-asg \
    --policy-name scale-up-policy \
    --scaling-adjustment 1 \
    --adjustment-type ChangeInCapacity
```

## S3 å¯¹è±¡å­˜å‚¨

### åŸºç¡€æ“ä½œ

```bash
# åˆ›å»º S3 å­˜å‚¨æ¡¶
aws s3 mb s3://my-unique-bucket-name-12345

# ä¸Šä¼ æ–‡ä»¶
aws s3 cp myfile.txt s3://my-unique-bucket-name-12345/
aws s3 cp myfolder/ s3://my-unique-bucket-name-12345/myfolder/ --recursive

# ä¸‹è½½æ–‡ä»¶
aws s3 cp s3://my-unique-bucket-name-12345/myfile.txt ./
aws s3 sync s3://my-unique-bucket-name-12345/myfolder/ ./myfolder/

# åˆ—å‡ºå¯¹è±¡
aws s3 ls s3://my-unique-bucket-name-12345/

# åˆ é™¤å¯¹è±¡
aws s3 rm s3://my-unique-bucket-name-12345/myfile.txt
aws s3 rm s3://my-unique-bucket-name-12345/myfolder/ --recursive
```

### S3 é™æ€ç½‘ç«™æ‰˜ç®¡

```json
{
  "IndexDocument": {
    "Suffix": "index.html"
  },
  "ErrorDocument": {
    "Key": "error.html"
  }
}
```

```bash
# é…ç½®é™æ€ç½‘ç«™æ‰˜ç®¡
aws s3 website s3://my-website-bucket --index-document index.html --error-document error.html

# è®¾ç½®å­˜å‚¨æ¡¶ç­–ç•¥ï¼ˆå…¬å¼€è®¿é—®ï¼‰
cat > bucket-policy.json << 'EOF'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicReadGetObject",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-website-bucket/*"
    }
  ]
}
EOF

aws s3api put-bucket-policy --bucket my-website-bucket --policy file://bucket-policy.json
```

### Node.js SDK æ“ä½œ

```javascript
const AWS = require('aws-sdk');

// é…ç½® AWS SDK
AWS.config.update({
  region: 'us-west-2',
  accessKeyId: process.env.AWS_ACCESS_KEY_ID,
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
});

const s3 = new AWS.S3();

class S3Service {
  // ä¸Šä¼ æ–‡ä»¶
  async uploadFile(bucketName, key, fileContent, contentType) {
    const params = {
      Bucket: bucketName,
      Key: key,
      Body: fileContent,
      ContentType: contentType,
      ACL: 'public-read'
    };

    try {
      const result = await s3.upload(params).promise();
      console.log('æ–‡ä»¶ä¸Šä¼ æˆåŠŸ:', result.Location);
      return result;
    } catch (error) {
      console.error('æ–‡ä»¶ä¸Šä¼ å¤±è´¥:', error);
      throw error;
    }
  }

  // è·å–æ–‡ä»¶
  async getFile(bucketName, key) {
    const params = {
      Bucket: bucketName,
      Key: key
    };

    try {
      const result = await s3.getObject(params).promise();
      return result.Body;
    } catch (error) {
      console.error('æ–‡ä»¶è·å–å¤±è´¥:', error);
      throw error;
    }
  }

  // ç”Ÿæˆé¢„ç­¾å URL
  async generatePresignedUrl(bucketName, key, expiresIn = 3600) {
    const params = {
      Bucket: bucketName,
      Key: key,
      Expires: expiresIn
    };

    try {
      const url = await s3.getSignedUrlPromise('getObject', params);
      return url;
    } catch (error) {
      console.error('ç”Ÿæˆé¢„ç­¾å URL å¤±è´¥:', error);
      throw error;
    }
  }

  // åˆ—å‡ºå¯¹è±¡
  async listObjects(bucketName, prefix = '') {
    const params = {
      Bucket: bucketName,
      Prefix: prefix
    };

    try {
      const result = await s3.listObjectsV2(params).promise();
      return result.Contents;
    } catch (error) {
      console.error('åˆ—å‡ºå¯¹è±¡å¤±è´¥:', error);
      throw error;
    }
  }

  // åˆ é™¤æ–‡ä»¶
  async deleteFile(bucketName, key) {
    const params = {
      Bucket: bucketName,
      Key: key
    };

    try {
      await s3.deleteObject(params).promise();
      console.log('æ–‡ä»¶åˆ é™¤æˆåŠŸ:', key);
    } catch (error) {
      console.error('æ–‡ä»¶åˆ é™¤å¤±è´¥:', error);
      throw error;
    }
  }
}

module.exports = S3Service;
```

## Lambda æ— æœåŠ¡å™¨è®¡ç®—

### åˆ›å»º Lambda å‡½æ•°

```javascript
// lambda/hello-world/index.js
exports.handler = async (event, context) => {
    console.log('Event: ', JSON.stringify(event, null, 2));
    console.log('Context: ', JSON.stringify(context, null, 2));

    const response = {
        statusCode: 200,
        headers: {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        },
        body: JSON.stringify({
            message: 'Hello from Lambda!',
            timestamp: new Date().toISOString(),
            requestId: context.awsRequestId
        })
    };

    return response;
};
```

### API Gateway é›†æˆ

```javascript
// lambda/api-handler/index.js
const AWS = require('aws-sdk');
const dynamodb = new AWS.DynamoDB.DocumentClient();

exports.handler = async (event, context) => {
    const { httpMethod, path, pathParameters, body } = event;
    
    try {
        let response;
        
        switch (httpMethod) {
            case 'GET':
                if (pathParameters && pathParameters.id) {
                    response = await getUser(pathParameters.id);
                } else {
                    response = await getAllUsers();
                }
                break;
                
            case 'POST':
                const userData = JSON.parse(body);
                response = await createUser(userData);
                break;
                
            case 'PUT':
                const updateData = JSON.parse(body);
                response = await updateUser(pathParameters.id, updateData);
                break;
                
            case 'DELETE':
                response = await deleteUser(pathParameters.id);
                break;
                
            default:
                response = {
                    statusCode: 405,
                    body: JSON.stringify({ error: 'Method not allowed' })
                };
        }
        
        return {
            ...response,
            headers: {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE',
                'Access-Control-Allow-Headers': 'Content-Type'
            }
        };
        
    } catch (error) {
        console.error('Error:', error);
        return {
            statusCode: 500,
            headers: {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            body: JSON.stringify({ 
                error: 'Internal server error',
                message: error.message 
            })
        };
    }
};

async function getAllUsers() {
    const params = {
        TableName: 'Users'
    };
    
    const result = await dynamodb.scan(params).promise();
    
    return {
        statusCode: 200,
        body: JSON.stringify({
            users: result.Items,
            count: result.Count
        })
    };
}

async function getUser(userId) {
    const params = {
        TableName: 'Users',
        Key: { id: userId }
    };
    
    const result = await dynamodb.get(params).promise();
    
    if (!result.Item) {
        return {
            statusCode: 404,
            body: JSON.stringify({ error: 'User not found' })
        };
    }
    
    return {
        statusCode: 200,
        body: JSON.stringify(result.Item)
    };
}

async function createUser(userData) {
    const user = {
        id: generateUUID(),
        ...userData,
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString()
    };
    
    const params = {
        TableName: 'Users',
        Item: user
    };
    
    await dynamodb.put(params).promise();
    
    return {
        statusCode: 201,
        body: JSON.stringify(user)
    };
}

function generateUUID() {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
        const r = Math.random() * 16 | 0;
        const v = c == 'x' ? r : (r & 0x3 | 0x8);
        return v.toString(16);
    });
}
```

### SAM æ¨¡æ¿éƒ¨ç½²

```yaml
# template.yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31

Globals:
  Function:
    Timeout: 30
    Runtime: nodejs18.x
    Environment:
      Variables:
        TABLE_NAME: !Ref UsersTable

Resources:
  # Lambda å‡½æ•°
  ApiFunction:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: lambda/api-handler/
      Handler: index.handler
      Policies:
        - DynamoDBCrudPolicy:
            TableName: !Ref UsersTable
      Events:
        GetUsers:
          Type: Api
          Properties:
            Path: /users
            Method: get
        GetUser:
          Type: Api
          Properties:
            Path: /users/{id}
            Method: get
        CreateUser:
          Type: Api
          Properties:
            Path: /users
            Method: post
        UpdateUser:
          Type: Api
          Properties:
            Path: /users/{id}
            Method: put
        DeleteUser:
          Type: Api
          Properties:
            Path: /users/{id}
            Method: delete

  # DynamoDB è¡¨
  UsersTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: Users
      AttributeDefinitions:
        - AttributeName: id
          AttributeType: S
      KeySchema:
        - AttributeName: id
          KeyType: HASH
      BillingMode: PAY_PER_REQUEST

Outputs:
  ApiUrl:
    Description: "API Gateway endpoint URL"
    Value: !Sub "https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/"
  
  FunctionName:
    Description: "Lambda Function Name"
    Value: !Ref ApiFunction
  
  TableName:
    Description: "DynamoDB Table Name"
    Value: !Ref UsersTable
```

```bash
# éƒ¨ç½² SAM åº”ç”¨
sam build
sam deploy --guided
```

## RDS å…³ç³»å‹æ•°æ®åº“

### åˆ›å»º RDS å®ä¾‹

```bash
# åˆ›å»º DB å­ç½‘ç»„
aws rds create-db-subnet-group \
    --db-subnet-group-name my-db-subnet-group \
    --db-subnet-group-description "My DB subnet group" \
    --subnet-ids subnet-12345678 subnet-87654321

# åˆ›å»º RDS å®ä¾‹
aws rds create-db-instance \
    --db-instance-identifier my-database \
    --db-instance-class db.t3.micro \
    --engine mysql \
    --engine-version 8.0.35 \
    --allocated-storage 20 \
    --master-username admin \
    --master-user-password MySecurePassword123 \
    --db-subnet-group-name my-db-subnet-group \
    --vpc-security-group-ids sg-12345678 \
    --backup-retention-period 7 \
    --multi-az \
    --storage-encrypted \
    --deletion-protection
```

### æ•°æ®åº“è¿æ¥å’Œæ“ä½œ

```javascript
// db/connection.js
const mysql = require('mysql2/promise');

class DatabaseConnection {
    constructor() {
        this.pool = mysql.createPool({
            host: process.env.DB_HOST,
            port: process.env.DB_PORT || 3306,
            user: process.env.DB_USER,
            password: process.env.DB_PASSWORD,
            database: process.env.DB_NAME,
            connectionLimit: 10,
            acquireTimeout: 60000,
            timeout: 60000
        });
    }

    async query(sql, params = []) {
        try {
            const [rows, fields] = await this.pool.execute(sql, params);
            return rows;
        } catch (error) {
            console.error('Database query error:', error);
            throw error;
        }
    }

    async getConnection() {
        return await this.pool.getConnection();
    }

    async closePool() {
        await this.pool.end();
    }
}

// ç”¨æˆ·æ“ä½œç±»
class UserRepository {
    constructor(db) {
        this.db = db;
    }

    async createUser(userData) {
        const { username, email, hashedPassword } = userData;
        const sql = `
            INSERT INTO users (username, email, password, created_at, updated_at)
            VALUES (?, ?, ?, NOW(), NOW())
        `;
        
        const result = await this.db.query(sql, [username, email, hashedPassword]);
        return { id: result.insertId, username, email };
    }

    async getUserById(id) {
        const sql = 'SELECT id, username, email, created_at FROM users WHERE id = ?';
        const users = await this.db.query(sql, [id]);
        return users[0] || null;
    }

    async getUserByEmail(email) {
        const sql = 'SELECT * FROM users WHERE email = ?';
        const users = await this.db.query(sql, [email]);
        return users[0] || null;
    }

    async updateUser(id, userData) {
        const { username, email } = userData;
        const sql = `
            UPDATE users 
            SET username = ?, email = ?, updated_at = NOW()
            WHERE id = ?
        `;
        
        await this.db.query(sql, [username, email, id]);
        return await this.getUserById(id);
    }

    async deleteUser(id) {
        const sql = 'DELETE FROM users WHERE id = ?';
        const result = await this.db.query(sql, [id]);
        return result.affectedRows > 0;
    }

    async getAllUsers(limit = 10, offset = 0) {
        const sql = `
            SELECT id, username, email, created_at 
            FROM users 
            ORDER BY created_at DESC 
            LIMIT ? OFFSET ?
        `;
        
        return await this.db.query(sql, [limit, offset]);
    }
}

module.exports = { DatabaseConnection, UserRepository };
```

## VPC ç½‘ç»œé…ç½®

### VPC åˆ›å»ºå’Œé…ç½®

```bash
# åˆ›å»º VPC
aws ec2 create-vpc --cidr-block 10.0.0.0/16 --tag-specifications 'ResourceType=vpc,Tags=[{Key=Name,Value=my-vpc}]'

# åˆ›å»ºå­ç½‘
# å…¬æœ‰å­ç½‘
aws ec2 create-subnet \
    --vpc-id vpc-12345678 \
    --cidr-block 10.0.1.0/24 \
    --availability-zone us-west-2a \
    --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value=public-subnet-1}]'

# ç§æœ‰å­ç½‘
aws ec2 create-subnet \
    --vpc-id vpc-12345678 \
    --cidr-block 10.0.2.0/24 \
    --availability-zone us-west-2b \
    --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value=private-subnet-1}]'

# åˆ›å»ºäº’è”ç½‘ç½‘å…³
aws ec2 create-internet-gateway --tag-specifications 'ResourceType=internet-gateway,Tags=[{Key=Name,Value=my-igw}]'

# é™„åŠ åˆ° VPC
aws ec2 attach-internet-gateway --vpc-id vpc-12345678 --internet-gateway-id igw-87654321

# åˆ›å»ºè·¯ç”±è¡¨
aws ec2 create-route-table --vpc-id vpc-12345678 --tag-specifications 'ResourceType=route-table,Tags=[{Key=Name,Value=public-rt}]'

# æ·»åŠ è·¯ç”±
aws ec2 create-route \
    --route-table-id rtb-12345678 \
    --destination-cidr-block 0.0.0.0/0 \
    --gateway-id igw-87654321

# å…³è”å­ç½‘åˆ°è·¯ç”±è¡¨
aws ec2 associate-route-table --subnet-id subnet-12345678 --route-table-id rtb-12345678
```

### CloudFormation æ¨¡æ¿

```yaml
# infrastructure.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'VPC Infrastructure with public and private subnets'

Parameters:
  VpcCidr:
    Type: String
    Default: '10.0.0.0/16'
    Description: CIDR block for VPC

Resources:
  # VPC
  MyVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VpcCidr
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: my-vpc

  # Internet Gateway
  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: my-igw

  InternetGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref InternetGateway
      VpcId: !Ref MyVPC

  # Public Subnets
  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      AvailabilityZone: !Select [ 0, !GetAZs '' ]
      CidrBlock: 10.0.1.0/24
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: Public Subnet AZ1

  PublicSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      AvailabilityZone: !Select [ 1, !GetAZs '' ]
      CidrBlock: 10.0.2.0/24
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: Public Subnet AZ2

  # Private Subnets
  PrivateSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      AvailabilityZone: !Select [ 0, !GetAZs '' ]
      CidrBlock: 10.0.11.0/24
      Tags:
        - Key: Name
          Value: Private Subnet AZ1

  PrivateSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      AvailabilityZone: !Select [ 1, !GetAZs '' ]
      CidrBlock: 10.0.12.0/24
      Tags:
        - Key: Name
          Value: Private Subnet AZ2

  # NAT Gateways
  NatGateway1EIP:
    Type: AWS::EC2::EIP
    DependsOn: InternetGatewayAttachment
    Properties:
      Domain: vpc

  NatGateway1:
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NatGateway1EIP.AllocationId
      SubnetId: !Ref PublicSubnet1

  # Route Tables
  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVPC
      Tags:
        - Key: Name
          Value: Public Routes

  DefaultPublicRoute:
    Type: AWS::EC2::Route
    DependsOn: InternetGatewayAttachment
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PublicRouteTable
      SubnetId: !Ref PublicSubnet1

  PublicSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PublicRouteTable
      SubnetId: !Ref PublicSubnet2

  PrivateRouteTable1:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVPC
      Tags:
        - Key: Name
          Value: Private Routes AZ1

  DefaultPrivateRoute1:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable1
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway1

  PrivateSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PrivateRouteTable1
      SubnetId: !Ref PrivateSubnet1

Outputs:
  VPC:
    Description: VPC ID
    Value: !Ref MyVPC
    Export:
      Name: !Sub ${AWS::StackName}-VPC

  PublicSubnets:
    Description: Public subnets
    Value: !Join [ ",", [ !Ref PublicSubnet1, !Ref PublicSubnet2 ]]
    Export:
      Name: !Sub ${AWS::StackName}-PublicSubnets

  PrivateSubnets:
    Description: Private subnets
    Value: !Join [ ",", [ !Ref PrivateSubnet1, !Ref PrivateSubnet2 ]]
    Export:
      Name: !Sub ${AWS::StackName}-PrivateSubnets
```

## IAM å®‰å…¨ç®¡ç†

### ç”¨æˆ·å’Œè§’è‰²ç®¡ç†

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::my-app-bucket/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::my-app-bucket"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:UpdateItem",
        "dynamodb:DeleteItem",
        "dynamodb:Query",
        "dynamodb:Scan"
      ],
      "Resource": [
        "arn:aws:dynamodb:us-west-2:123456789012:table/my-table"
      ]
    }
  ]
}
```

### Lambda æ‰§è¡Œè§’è‰²

```bash
# åˆ›å»ºä¿¡ä»»ç­–ç•¥
cat > trust-policy.json << 'EOF'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "lambda.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
EOF

# åˆ›å»ºè§’è‰²
aws iam create-role \
    --role-name lambda-execution-role \
    --assume-role-policy-document file://trust-policy.json

# é™„åŠ ç­–ç•¥
aws iam attach-role-policy \
    --role-name lambda-execution-role \
    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

# é™„åŠ è‡ªå®šä¹‰ç­–ç•¥
aws iam attach-role-policy \
    --role-name lambda-execution-role \
    --policy-arn arn:aws:iam::123456789012:policy/my-custom-policy
```

## ç›‘æ§å’Œæ—¥å¿—

### CloudWatch ç›‘æ§

```javascript
// cloudwatch-metrics.js
const AWS = require('aws-sdk');
const cloudwatch = new AWS.CloudWatch();

class MetricsService {
    async putMetric(metricName, value, unit = 'Count', namespace = 'MyApp') {
        const params = {
            Namespace: namespace,
            MetricData: [
                {
                    MetricName: metricName,
                    Value: value,
                    Unit: unit,
                    Timestamp: new Date()
                }
            ]
        };

        try {
            await cloudwatch.putMetricData(params).promise();
            console.log(`Metric ${metricName} sent successfully`);
        } catch (error) {
            console.error('Error sending metric:', error);
        }
    }

    async putCustomMetric(metricData) {
        const params = {
            Namespace: metricData.namespace || 'MyApp',
            MetricData: [
                {
                    MetricName: metricData.name,
                    Value: metricData.value,
                    Unit: metricData.unit || 'Count',
                    Dimensions: metricData.dimensions || [],
                    Timestamp: new Date()
                }
            ]
        };

        try {
            await cloudwatch.putMetricData(params).promise();
        } catch (error) {
            console.error('Error sending custom metric:', error);
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
const metrics = new MetricsService();

// è®°å½•APIè°ƒç”¨æ¬¡æ•°
await metrics.putMetric('ApiCalls', 1);

// è®°å½•å“åº”æ—¶é—´
await metrics.putCustomMetric({
    name: 'ResponseTime',
    value: 150,
    unit: 'Milliseconds',
    dimensions: [
        {
            Name: 'Endpoint',
            Value: '/api/users'
        }
    ]
});
```

### CloudWatch Logs

```javascript
// logger.js
const AWS = require('aws-sdk');
const cloudwatchlogs = new AWS.CloudWatchLogs();

class Logger {
    constructor(logGroupName, logStreamName) {
        this.logGroupName = logGroupName;
        this.logStreamName = logStreamName;
        this.sequenceToken = null;
    }

    async createLogGroup() {
        try {
            await cloudwatchlogs.createLogGroup({
                logGroupName: this.logGroupName
            }).promise();
        } catch (error) {
            if (error.code !== 'ResourceAlreadyExistsException') {
                throw error;
            }
        }
    }

    async createLogStream() {
        try {
            await cloudwatchlogs.createLogStream({
                logGroupName: this.logGroupName,
                logStreamName: this.logStreamName
            }).promise();
        } catch (error) {
            if (error.code !== 'ResourceAlreadyExistsException') {
                throw error;
            }
        }
    }

    async log(message, level = 'INFO') {
        const logEvent = {
            message: JSON.stringify({
                level,
                message,
                timestamp: new Date().toISOString()
            }),
            timestamp: Date.now()
        };

        const params = {
            logGroupName: this.logGroupName,
            logStreamName: this.logStreamName,
            logEvents: [logEvent]
        };

        if (this.sequenceToken) {
            params.sequenceToken = this.sequenceToken;
        }

        try {
            const result = await cloudwatchlogs.putLogEvents(params).promise();
            this.sequenceToken = result.nextSequenceToken;
        } catch (error) {
            console.error('Error sending log:', error);
        }
    }
}

module.exports = Logger;
```

## CI/CD å’Œéƒ¨ç½²

### CodePipeline é…ç½®

```yaml
# buildspec.yml
version: 0.2

phases:
  pre_build:
    commands:
      - echo Logging in to Amazon ECR...
      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
      - REPOSITORY_URI=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME
      - COMMIT_HASH=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7)
      - IMAGE_TAG=${COMMIT_HASH:=latest}
  build:
    commands:
      - echo Build started on `date`
      - echo Building the Docker image...
      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .
      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $REPOSITORY_URI:$IMAGE_TAG
  post_build:
    commands:
      - echo Build completed on `date`
      - echo Pushing the Docker image...
      - docker push $REPOSITORY_URI:$IMAGE_TAG
      - echo Writing image definitions file...
      - printf '[{"name":"my-app","imageUri":"%s"}]' $REPOSITORY_URI:$IMAGE_TAG > imagedefinitions.json

artifacts:
  files:
    - imagedefinitions.json
```

### Terraform åŸºç¡€è®¾æ–½å³ä»£ç 

```hcl
# main.tf
provider "aws" {
  region = var.aws_region
}

# VPC
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "${var.project_name}-vpc"
  }
}

# Internet Gateway
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = {
    Name = "${var.project_name}-igw"
  }
}

# Public Subnets
resource "aws_subnet" "public" {
  count = length(var.public_subnet_cidrs)

  vpc_id                  = aws_vpc.main.id
  cidr_block              = var.public_subnet_cidrs[count.index]
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true

  tags = {
    Name = "${var.project_name}-public-subnet-${count.index + 1}"
    Type = "Public"
  }
}

# ECS Cluster
resource "aws_ecs_cluster" "main" {
  name = "${var.project_name}-cluster"

  setting {
    name  = "containerInsights"
    value = "enabled"
  }
}

# ECS Task Definition
resource "aws_ecs_task_definition" "app" {
  family                   = "${var.project_name}-app"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = var.fargate_cpu
  memory                   = var.fargate_memory
  execution_role_arn       = aws_iam_role.ecs_task_execution_role.arn

  container_definitions = jsonencode([
    {
      name      = "my-app"
      image     = "${var.app_image}:${var.app_version}"
      essential = true
      portMappings = [
        {
          containerPort = var.app_port
          hostPort      = var.app_port
        }
      ]
      logConfiguration = {
        logDriver = "awslogs"
        options = {
          awslogs-group         = "/ecs/${var.project_name}"
          awslogs-region        = var.aws_region
          awslogs-stream-prefix = "ecs"
        }
      }
      environment = [
        {
          name  = "NODE_ENV"
          value = "production"
        }
      ]
    }
  ])
}

# Variables
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-west-2"
}

variable "project_name" {
  description = "Name of the project"
  type        = string
  default     = "my-app"
}

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
}

variable "public_subnet_cidrs" {
  description = "CIDR blocks for public subnets"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24"]
}
```

## æˆæœ¬ä¼˜åŒ–

### æˆæœ¬ç›‘æ§å’Œé¢„ç®—

```bash
# åˆ›å»ºæˆæœ¬é¢„ç®—
aws budgets create-budget \
    --account-id 123456789012 \
    --budget '{
        "BudgetName": "Monthly-Budget",
        "BudgetLimit": {
            "Amount": "100.0",
            "Unit": "USD"
        },
        "TimeUnit": "MONTHLY",
        "BudgetType": "COST",
        "CostFilters": {}
    }' \
    --notifications-with-subscribers '[
        {
            "Notification": {
                "NotificationType": "ACTUAL",
                "ComparisonOperator": "GREATER_THAN",
                "Threshold": 80,
                "ThresholdType": "PERCENTAGE"
            },
            "Subscribers": [
                {
                    "SubscriptionType": "EMAIL",
                    "Address": "admin@example.com"
                }
            ]
        }
    ]'
```

### æœ€ä½³å®è·µ

```javascript
// æˆæœ¬ä¼˜åŒ–å»ºè®®
const costOptimization = {
    ec2: {
        // ä½¿ç”¨åˆé€‚çš„å®ä¾‹ç±»å‹
        rightSizing: "å®šæœŸå®¡æŸ¥å®ä¾‹ä½¿ç”¨æƒ…å†µï¼Œé€‰æ‹©åˆé€‚å¤§å°",
        spotInstances: "å¯¹äºå®¹é”™å·¥ä½œè´Ÿè½½ä½¿ç”¨ Spot å®ä¾‹",
        reservedInstances: "å¯¹äºç¨³å®šå·¥ä½œè´Ÿè½½è´­ä¹°é¢„ç•™å®ä¾‹",
        autoShutdown: "ä¸ºå¼€å‘ç¯å¢ƒè®¾ç½®è‡ªåŠ¨å…³æœºè®¡åˆ’"
    },
    
    storage: {
        s3LifecyclePolicy: "è®¾ç½® S3 ç”Ÿå‘½å‘¨æœŸç­–ç•¥ï¼Œè‡ªåŠ¨è½¬ç§»åˆ°æ›´ä¾¿å®œçš„å­˜å‚¨ç±»",
        ebsOptimization: "åˆ é™¤æœªä½¿ç”¨çš„ EBS å·å’Œå¿«ç…§",
        compressionAndDeduplication: "ä½¿ç”¨å‹ç¼©å’Œå»é‡æŠ€æœ¯"
    },
    
    networking: {
        dataTransfer: "æœ€å°åŒ–è·¨åŒºåŸŸæ•°æ®ä¼ è¾“",
        cloudfront: "ä½¿ç”¨ CloudFront å‡å°‘æºç«™è´Ÿè½½",
        directConnect: "å¯¹äºå¤§é‡æ•°æ®ä¼ è¾“è€ƒè™‘ Direct Connect"
    },
    
    monitoring: {
        cloudwatch: "è®¾ç½®æˆæœ¬å¼‚å¸¸æ£€æµ‹",
        costExplorer: "å®šæœŸåˆ†ææˆæœ¬è¶‹åŠ¿",
        tagging: "ä½¿ç”¨æ ‡ç­¾è¿›è¡Œæˆæœ¬åˆ†é…å’Œè·Ÿè¸ª"
    }
};
```

## æ€»ç»“

AWS äº‘æœåŠ¡ä¸ºç°ä»£åº”ç”¨æä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆï¼š

âœ¨ **å¼¹æ€§å’Œå¯æ‰©å±•æ€§**ï¼šæŒ‰éœ€æ‰©ç¼©å®¹ï¼Œåº”å¯¹ä¸šåŠ¡å¢é•¿  
âœ¨ **é«˜å¯ç”¨æ€§**ï¼šå¤šåŒºåŸŸéƒ¨ç½²ï¼Œä¿è¯æœåŠ¡è¿ç»­æ€§  
âœ¨ **å®‰å…¨æ€§**ï¼šå¤šå±‚æ¬¡å®‰å…¨é˜²æŠ¤ï¼Œä¿æŠ¤æ•°æ®å®‰å…¨  
âœ¨ **æˆæœ¬æ•ˆç›Š**ï¼šæŒ‰ä½¿ç”¨é‡ä»˜è´¹ï¼Œä¼˜åŒ–æˆæœ¬æ”¯å‡º  
âœ¨ **ä¸°å¯Œçš„æœåŠ¡**ï¼šæ¶µç›–è®¡ç®—ã€å­˜å‚¨ã€æ•°æ®åº“ã€AI ç­‰å„ä¸ªé¢†åŸŸ  

æŒæ¡ AWS äº‘æœåŠ¡ï¼Œè®©ä½ çš„åº”ç”¨æ›´åŠ ç°ä»£åŒ–ã€å¯é ã€é«˜æ•ˆï¼

---

*äº‘è®¡ç®—æ”¹å˜ä¸–ç•Œï¼ŒAWS åŠ©åŠ›ä¼ä¸šæ•°å­—åŒ–è½¬å‹ï¼*
